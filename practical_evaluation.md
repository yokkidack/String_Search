## Сравнение алгоритмов поиска подстроки по проведенным тестам.

### Методика

Для каждого алгоритма были проведены тесты на случайном тексте с алфавитом из
букв {a,b,c,d} и из букв начиная с буквы 'a' и заканчивая буквой 'z'.

Для каждого алгоритма и каждого алфавита проводилось по 100 поисков последних 10 и 100
(20 и 200, соответственно, для строк длинной 10^7) символов в строке. Строки были 10^3, 10^4, 10^5, 10^6, 10^7
символов в длину.

Тесты для подстрок длины 10 запускались последовательно, сначала для одного алфавита с последовательным
прохождением всех тестов для некоторого алгоритма в порядке увеличения длины строки, потом процедура
повторялась для второго алфавита. После этого повторялось все тоже самое для подслов длины 100.

Результаты выводились в таблицу и по ним были построены графики.

Перед проведением тестов, все тесты прогонялись один раз без сохранения результатов
чтобы предиктор процессора вышел на необходимую скорость. Как показали предворительные тесты,
результат может отличаться болеее чем в три раза на замерах с строкой длины 10^7, при
проведении теста с холостым прогоном против теста без холостого прогона.

Однако результаты сильно отличались в зависомости от порядка выполнения тестов.

`Примечание`:
Все тестовые файлы генерировались скриптом и не будут приложены к проекту в силу большого обьема, однако в папке scripts можно найти этот скрипт который сгенерирует все эти файлы для заинтересованного читателя. Однако, когда я попробовал генерировать файлы больше 10^7 символов в длину это занимало очень продолжительное время, окончания я так и не дождался.

### Гипотезы.

Алгоритм Бойера Мура на 4 буквенно алфавите должен показать себя немного хуже чем на многобуквенно, несмотря на дополнительные затраты на построение таблицы плохих символов, большая вариативность окон строки в силу разности символов алфавита должна позволить этому алгоритму проводить эффективные сдвиги по таблице.

Скорее всего Наивный Алгоритм будет самым медленным, хотя, возможно на маленькой длине он всеже выйдет вперыд в силу маленького коэффициента.

Рабин Карп должен показать себя одинаково на обоих алфавитах. Также скорее всего он вырвется вперед на длинных подстроках в силу достаточно дорогого хэширования, отбивающего свою цену на длинных подстроках. (Хэш используется так называемый "rolling hash", он считается за линейное время от длины входного подслова в первый раз и за константу для последующих подслов, если они идут со сдвигом в 1 символ (а они так и идут))

Алгоритм Кнутта - Морриса - Пратта скорее всего обгонит всех, он считается самым быстрым алгоритмом общего назначения.

### Результаты.

![10-30](/img/needle10letters30.png)

`Поиск подстроки длины 10 с "полным" алфавитом`

![10-4](/img/needle10letters4.png)

`Поиск подстроки длины 10 с "коротким" алфавитом`

![100-30](/img/needle100letters30.png)

`Поиск подстроки длины 100 с "полным" алфавитом`

![100-4](/img/needle100letters4.png)

`Поиск подстроки длины 100 с "коротким" алфавитом`

Еще один тест я назвал "ААА тест". На вход каждому алгоритму давалась строка длиной в миллион + 1 знак, миллион букв 'a' - как символ моего внетреннего состояния, и одна буква 'b'. Этот тест сводился к гонке. Каждому алгоритму нужно было найти вхождение подстроки длиной в сто один символ (сто букв а и одна буква b).

![AAAAAAAA](/img/AAAtest.png)

На диаграмме видно время выполнения 100 таких поисков.
Также видно что алгоритмы, которым не нужно сравнивать все символы между собой доминируют над Наивным Алгоритмом.

### Выводы

Алгоритм Кнутта - Морриса - Пратта почти всегда самый лучший на случайных данных. Однако есть модификация, которая еще больше повышает его эффективность.

Алгоритм Рабина Карпа, к сожалению всегда отставал на случайных данных. Скорее всего это из-за очень дорогих вычислений хэша.

Алгоритм Бойера Мура на случайных данных не показал того, что я от него ожидал. На разных алфавитах результаты примерно одинаковы.

Наивный алгоритм не показал себя хуже всех на случайных данных. Но он явно хуже двух других показавших себя алгоритмах.
